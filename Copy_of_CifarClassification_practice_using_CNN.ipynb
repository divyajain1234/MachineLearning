{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyajain1234/MachineLearning/blob/main/Copy_of_CifarClassification_practice_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxVCkI5OMu3"
      },
      "source": [
        "Loading modules and dataset\n",
        "The very first thing to do when we are about to write a code is importing all required modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh6cLIJLljuP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqMILP-OOfxK"
      },
      "source": [
        "The CIFAR-10 dataset itself can either be downloaded manually from this link or directly through the code (using API).the dataset size itself is around 160 MB. After the code finishes running, the dataset is going to be stored automatically to X_train, y_train, X_test and y_test variables, where the training and testing data itself consist of 50000 and 10000 samples respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x19DWmgl51g"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XkA7q4qOysw"
      },
      "source": [
        "The code below tells the computer that we are about to display the first 50 images in the dataset which are divided into 10 columns and 5 rows. The figsize argument is used just to define the size of our figure. We can see here that I am going to set the title using set_title() and display the images using imshow()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a656Ez8EmOxq"
      },
      "outputs": [],
      "source": [
        "labels = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "fig, axes = plt.subplots(ncols=10, nrows=5, figsize=(17, 8))\n",
        "index = 0\n",
        "for i in range(5):\n",
        "    for j in range(10):\n",
        "        axes[i,j].set_title(labels[y_train[index][0]])\n",
        "        axes[i,j].imshow(X_train[index])\n",
        "        axes[i,j].get_xaxis().set_visible(False)\n",
        "        axes[i,j].get_yaxis().set_visible(False)\n",
        "        index += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGT07eC3PDN8"
      },
      "source": [
        "convert all those images (both train and test data) into grayscale.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jbPjnK8n6gA"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_train])\n",
        "X_test = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWDPcwZpPig9"
      },
      "source": [
        "Now picutre in gray\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8XZGPbDPw5-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0ML6w2joL3b"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=7, nrows=3, figsize=(17, 8))\n",
        "index = 0\n",
        "for i in range(3):\n",
        "    for j in range(7):\n",
        "        axes[i,j].set_title(labels[y_train[index][0]])\n",
        "        axes[i,j].imshow(X_train[index], cmap='gray')\n",
        "        axes[i,j].get_xaxis().set_visible(False)\n",
        "        axes[i,j].get_yaxis().set_visible(False)\n",
        "        index += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJAevIzpP6Jf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NadcDI9YPzqD"
      },
      "source": [
        "normalize array values. We know that by default the brightness of each pixel in any image are represented using a value which ranges between 0 and 255. In order for neural network to work best, we need to convert this value such that itâ€™s going to be in the range between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Golm9usEoRUV"
      },
      "outputs": [],
      "source": [
        "X_train  = X_train/255\n",
        "X_test  = X_test/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoPSYqml-f8R"
      },
      "source": [
        "Data preprcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP9k6W3ZopE8"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "one_hot_encoder.fit(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca8jix9LuVNa"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder = OneHotEncoder( sparse_output=False)\n",
        "one_hot_encoder.fit(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MIXfC1Bvj5q"
      },
      "outputs": [],
      "source": [
        "y_train = one_hot_encoder.transform(y_train)\n",
        "y_test = one_hot_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzrGwL1XQbCi"
      },
      "source": [
        "the shape of X_train and X_test, the size will be (50000, 32, 32) and (10000, 32, 32) respectively. Well, actually this shape is not acceptable by Conv2D layer that we are going to implement. So, we need to reshape those two arrays using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfmlGWu2sYtM"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ3Qe2jCQly8"
      },
      "source": [
        "Now our X_train and X_test shapes are going to be (50000, 32, 32, 1) and (10000, 32, 32, 1), where the number 1 in the last position indicates that we are now using only 1 color channel (gray)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69BY0cK3tEAB"
      },
      "outputs": [],
      "source": [
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ey8w27QR1Uu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvf95mUF_E3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt-pD-eMs5WN"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1),\n",
        "    padding='same', input_shape=input_shape))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1),\n",
        "    padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1),\n",
        "    padding='same'))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1),\n",
        "    padding='same'))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1),\n",
        "    padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1),\n",
        "    padding='same'))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgvv6Ej3vqLd"
      },
      "outputs": [],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhil4R65x8Nn"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "     optimizer='adam',\n",
        "     metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VArF-7R-yC3O"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC9r4CgZvI2p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doe3Ywhz3ryM"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg_dFRGly5Pg"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=9, batch_size=200, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pjlEkX1rCJg"
      },
      "outputs": [],
      "source": [
        "# Generate generalization metrics\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Validation accuracy history')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuLGi_KzJu3Z"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"val_acc\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1dtMFOFKfep"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ2mHAyHK3rG"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = one_hot_encoder.inverse_transform(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDt6BVOTLVVS"
      },
      "outputs": [],
      "source": [
        "y_test = one_hot_encoder.inverse_transform(y_test)\n",
        "y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q978Y6PKLkcy"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeZpLWvkLr_7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, cbar=False, xticklabels=labels, yticklabels=labels, fmt=\"d\", annot=True, cmap=plt.cm.Blues)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm3BkMWyMPjV"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maoqb8kXMpRW"
      },
      "outputs": [],
      "source": [
        "y_test = y_test.astype(int)\n",
        "predictions = predictions.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLQLGLqNMyZa"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=7, nrows=3, sharex=False,\n",
        "    sharey=True, figsize=(17, 8))\n",
        "index = 0\n",
        "for i in range(3):\n",
        "    for j in range(7):\n",
        "        axes[i,j].set_title('actual:' + labels[y_test[index][0]] + '\\n'\n",
        "                            + 'predicted:' + labels[predictions[index][0]])\n",
        "        axes[i,j].imshow(X_test[index], cmap='gray')\n",
        "        axes[i,j].get_xaxis().set_visible(False)\n",
        "        axes[i,j].get_yaxis().set_visible(False)\n",
        "        index += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Dn_iJZOHY2"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}